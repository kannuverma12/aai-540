{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e6e99a",
   "metadata": {},
   "source": [
    "\n",
    "# üéì Enterprise Credit Risk ML System  \n",
    "## MS-Level Final Project ‚Äì Production-Grade SageMaker Implementation\n",
    "\n",
    "This notebook implements a full end-to-end MLOps system:\n",
    "\n",
    "- Data validation & preprocessing\n",
    "- Feature Store (online + offline)\n",
    "- XGBoost training with evaluation\n",
    "- SageMaker Pipeline (CI/CD DAG)\n",
    "- Model Registry governance\n",
    "- Real-time & Batch inference\n",
    "- Data Drift monitoring (PSI thresholds)\n",
    "- Model Quality Monitoring\n",
    "- Model Bias Monitoring (Clarify)\n",
    "- SHAP Explainability\n",
    "- CloudWatch alarms\n",
    "- Cleanup & cost control\n",
    "\n",
    "Author: Karan Verma  \n",
    "Course: AAI-540  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5a6e7",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23566799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_execution_role' from 'sagemaker' (/Users/rajni/opt/anaconda3/lib/python3.9/site-packages/sagemaker/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, roc_auc_score\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_execution_role\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Session\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingInput\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_execution_role' from 'sagemaker' (/Users/rajni/opt/anaconda3/lib/python3.9/site-packages/sagemaker/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.model_step import RegisterModel\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.model_monitor import DefaultModelMonitor, DatasetFormat\n",
    "from sagemaker.model_monitor import ModelBiasMonitor\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    "    SageMakerClarifyProcessor\n",
    ")\n",
    "\n",
    "session = Session()\n",
    "pipeline_session = PipelineSession()\n",
    "role = get_execution_role()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(\"Region:\", region)\n",
    "print(\"Bucket:\", bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21113472",
   "metadata": {},
   "source": [
    "Create Bucket and upload file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Use default SageMaker bucket (recommended)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix = \"credit-risk/raw\"\n",
    "\n",
    "print(\"Using bucket:\", bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f906d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path = \"credit.csv\"\n",
    "\n",
    "s3_path = sagemaker_session.upload_data(\n",
    "    path=local_file_path,\n",
    "    bucket=bucket,\n",
    "    key_prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"File uploaded to:\", s3_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe34b8b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Data Validation & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baacffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (must already exist in S3)\n",
    "data_path = f\"s3://{bucket}/credit-risk/raw/credit.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Basic validation\n",
    "assert 'credit_score_label' in df.columns, \"Target column missing\"\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['income_to_debt_ratio'] = df['income'] / (df['debt'] + 1)\n",
    "df['delinquency_flag'] = (df['late_payments'] > 0).astype(int)\n",
    "\n",
    "# Train-test split\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['credit_score_label'], random_state=42)\n",
    "\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "session.upload_data(\"train.csv\", bucket=bucket, key_prefix=\"credit-risk/train\")\n",
    "session.upload_data(\"test.csv\", bucket=bucket, key_prefix=\"credit-risk/test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9d8fe",
   "metadata": {},
   "source": [
    "‚úÖ 1. SageMaker Feature Store Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = Session()\n",
    "\n",
    "feature_store_session = sagemaker.Session()\n",
    "feature_group_name = \"credit-risk-feature-group\"\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name,\n",
    "    sagemaker_session=feature_store_session\n",
    ")\n",
    "\n",
    "df['event_time'] = pd.Timestamp.now().astype('datetime64[ns]')\n",
    "df['record_id'] = df.index.astype(str)\n",
    "\n",
    "feature_group.load_feature_definitions(data_frame=df)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://credit-risk-processed-data/feature-store\",\n",
    "    record_identifier_name=\"record_id\",\n",
    "    event_time_feature_name=\"event_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "\n",
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab068d14",
   "metadata": {},
   "source": [
    "Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530f81a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Model Training (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb = XGBoost(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"1.5-1\",\n",
    "    hyperparameters={\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 4,\n",
    "        \"max_depth\": 6,\n",
    "        \"eta\": 0.1,\n",
    "        \"subsample\": 0.8,\n",
    "        \"num_round\": 300\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb.fit({\n",
    "    \"train\": TrainingInput(f\"s3://{bucket}/credit-risk/train/train.csv\", content_type=\"text/csv\"),\n",
    "    \"validation\": TrainingInput(f\"s3://{bucket}/credit-risk/test/test.csv\", content_type=\"text/csv\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe76a9",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b38c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_package = xgb.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    model_package_group_name=\"CreditRiskModelGroup\",\n",
    "    approval_status=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "print(\"Model registered in Model Registry\")\n",
    "\n",
    "# from sagemaker.model_registry.model_package import ModelPackage\n",
    "\n",
    "# model_package = training_step.get_expected_model()\n",
    "\n",
    "# model_package.register(\n",
    "#     content_types=[\"text/csv\"],\n",
    "#     response_types=[\"application/json\"],\n",
    "#     inference_instances=[\"ml.t3.medium\"],\n",
    "#     model_package_group_name=\"CreditRiskModelGroup\",\n",
    "#     approval_status=\"PendingManualApproval\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdca928",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Real-Time Endpoint Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor = xgb.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t3.medium\"\n",
    ")\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "print(\"Endpoint deployed:\", endpoint_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4f1aa",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Model Quality Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a336ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quality_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    max_runtime_in_seconds=3600\n",
    ")\n",
    "\n",
    "quality_monitor.suggest_baseline(\n",
    "    baseline_dataset=f\"s3://{bucket}/credit-risk/test/test.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=f\"s3://{bucket}/monitoring/quality-baseline\"\n",
    ")\n",
    "\n",
    "# from sagemaker.model_monitor import ModelQualityMonitor\n",
    "\n",
    "# model_quality_monitor = ModelQualityMonitor(\n",
    "#     role=role,\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.large\",\n",
    "#     sagemaker_session=sagemaker_session\n",
    "# )\n",
    "\n",
    "# model_quality_monitor.create_monitoring_schedule(\n",
    "#     monitor_schedule_name=\"credit-risk-model-quality-monitor\",\n",
    "#     endpoint_input=endpoint_name,\n",
    "#     output_s3_uri=\"s3://credit-risk-monitoring/model-quality\",\n",
    "#     problem_type=\"BinaryClassification\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde34de",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Data Drift Monitoring (PSI Thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drift_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "drift_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=\"credit-risk-drift-monitor\",\n",
    "    endpoint_input=sagemaker.model_monitor.EndpointInput(\n",
    "        endpoint_name=endpoint_name,\n",
    "        destination=\"/opt/ml/processing/input\"\n",
    "    ),\n",
    "    output_s3_uri=f\"s3://{bucket}/monitoring/drift-reports\",\n",
    "    statistics=quality_monitor.baseline_statistics(),\n",
    "    constraints=quality_monitor.suggested_constraints()\n",
    ")\n",
    "\n",
    "# from sagemaker.model_monitor import DefaultModelMonitor\n",
    "\n",
    "# data_monitor = DefaultModelMonitor(\n",
    "#     role=role,\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.large\",\n",
    "#     sagemaker_session=sagemaker_session\n",
    "# )\n",
    "\n",
    "# data_monitor.create_monitoring_schedule(\n",
    "#     monitor_schedule_name=\"credit-risk-data-drift-monitor\",\n",
    "#     endpoint_input=endpoint_name,\n",
    "#     output_s3_uri=\"s3://credit-risk-monitoring/data-drift\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd010a",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Model Bias Monitoring (Clarify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50053530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bias_config = BiasConfig(\n",
    "    label_values_or_threshold=[1],\n",
    "    facet_name=\"gender\"\n",
    ")\n",
    "\n",
    "data_config = DataConfig(\n",
    "    s3_data_input_path=f\"s3://{bucket}/credit-risk/test/test.csv\",\n",
    "    s3_output_path=f\"s3://{bucket}/monitoring/bias\",\n",
    "    label=\"credit_score_label\",\n",
    "    dataset_type=\"text/csv\"\n",
    ")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name=endpoint_name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"application/json\"\n",
    ")\n",
    "\n",
    "bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "bias_monitor.suggest_baseline(\n",
    "    bias_config=bias_config,\n",
    "    data_config=data_config,\n",
    "    model_config=model_config\n",
    ")\n",
    "\n",
    "\n",
    "# from sagemaker import clarify\n",
    "\n",
    "# clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "#     role=role,\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.large\",\n",
    "#     sagemaker_session=sagemaker_session\n",
    "# )\n",
    "\n",
    "# bias_config = clarify.BiasConfig(\n",
    "#     label_values_or_threshold=[1],\n",
    "#     facet_name=\"Gender\",\n",
    "#     facet_values_or_threshold=[\"Female\"]\n",
    "# )\n",
    "\n",
    "# clarify_processor.run_bias(\n",
    "#     data_config=data_config,\n",
    "#     bias_config=bias_config,\n",
    "#     model_config=model_config\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea80f1b",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ SHAP Explainability (Clarify Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clarify_processor = SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "shap_config = SHAPConfig(\n",
    "    baseline=[0]* (len(train.columns)-1),\n",
    "    num_samples=100\n",
    ")\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")\n",
    "\n",
    "# import shap\n",
    "\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# shap.summary_plot(shap_values, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664840e",
   "metadata": {},
   "source": [
    "## üîü CloudWatch Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca02936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cloudwatch = boto3.client(\"cloudwatch\")\n",
    "\n",
    "cloudwatch.put_metric_alarm(\n",
    "    AlarmName=\"HighEndpointLatency\",\n",
    "    MetricName=\"ModelLatency\",\n",
    "    Namespace=\"AWS/SageMaker\",\n",
    "    Statistic=\"Average\",\n",
    "    Period=60,\n",
    "    EvaluationPeriods=2,\n",
    "    Threshold=1000.0,\n",
    "    ComparisonOperator=\"GreaterThanThreshold\",\n",
    "    Dimensions=[{\"Name\": \"EndpointName\", \"Value\": endpoint_name}]\n",
    ")\n",
    "print(\"Latency alarm configured\")\n",
    "\n",
    "# import boto3\n",
    "\n",
    "# cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# cloudwatch.put_metric_alarm(\n",
    "#     AlarmName='CreditRisk-HighErrorRate',\n",
    "#     MetricName='5XXError',\n",
    "#     Namespace='AWS/SageMaker',\n",
    "#     Statistic='Sum',\n",
    "#     Threshold=5.0,\n",
    "#     ComparisonOperator='GreaterThanThreshold',\n",
    "#     EvaluationPeriods=1,\n",
    "#     Period=300\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65887360",
   "metadata": {},
   "source": [
    "Evaluation Metrics Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3cfb",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Run After Demo to Avoid Charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictor.delete_endpoint()\n",
    "# predictor.delete_model()\n",
    "print(\"Cleanup section ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a5d44",
   "metadata": {},
   "source": [
    "‚úÖ 2. SageMaker Pipeline DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f31cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, ProcessingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=\"CreditRiskPipeline\",\n",
    "    parameters=[model_approval_status],\n",
    "    steps=[processing_step, training_step],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bfe2d4",
   "metadata": {},
   "source": [
    "Demonstration Script Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049109bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate inference\n",
    "\n",
    "sample = X_test.iloc[0:1]\n",
    "prediction = predictor.predict(sample.values.tolist())\n",
    "\n",
    "print(\"Predicted Class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2534428",
   "metadata": {},
   "source": [
    "# üèó Enterprise Architecture Diagram\n",
    "\n",
    "Data Sources\n",
    "    ‚Üì\n",
    "S3 Raw Layer\n",
    "    ‚Üì\n",
    "Feature Store\n",
    "    ‚Üì\n",
    "SageMaker Processing\n",
    "    ‚Üì\n",
    "Training Job\n",
    "    ‚Üì\n",
    "Model Registry\n",
    "    ‚Üì\n",
    "Endpoint Deployment\n",
    "    ‚Üì\n",
    "Model Monitor + Clarify\n",
    "    ‚Üì\n",
    "CloudWatch Dashboard\n",
    "\n",
    "\n",
    "# ‚ö† Risks\n",
    "\n",
    "- Historical bias in training data\n",
    "- Data drift due to economic changes\n",
    "- Regulatory compliance expansion required\n",
    "\n",
    "# üöÄ Future Improvements\n",
    "\n",
    "- Online retraining pipeline\n",
    "- Bayesian hyperparameter tuning\n",
    "- Fairness-constrained optimization\n",
    "- Multi-region deployment\n",
    "- Explainability API endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ac9786a0f64ca5b19301b7c5150fe9bb4f7e1402f0ec1e8500605c0f9e9ab6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
